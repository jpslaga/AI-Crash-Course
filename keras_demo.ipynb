{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpslaga/AI-Crash-Course/blob/master/keras_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTruGnVGJnBa",
        "colab_type": "text"
      },
      "source": [
        "###Imports\n",
        "In Python we start by importing modules. These modules have to be properly loaded on your Python processing machine. Google's colab.research.google.com website handles these dependencies for us. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hHVRTZDI7J3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mnist\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mnist\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zMNYPMUKBDB",
        "colab_type": "text"
      },
      "source": [
        "### Datasets\n",
        "The `mnist` module downloads the 'MNIST' database. The MNIST database (Modified National Institute of Standards and Technology database) is a large database of 600,000 handwritten digits that is commonly used for training various image processing systems, that's why it's so easy to get. \n",
        "- The images are stored as an array of grayscale values from 0-255. They are returned by `mnist.train_images()`.\n",
        "- The images are labeled with integers in a list returned by `mnist.train_labels()`\n",
        "- By default, there is a completely separate dataset for testing your trained machine learning tool, `mnist.test_images()` and `mnist.test_labels()`.\n",
        "- There are 60,000 training images and 10,000 test images, formatted identically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HNSjuALJXao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = mnist.train_images() #len: 60000\n",
        "train_labels = mnist.train_labels() #len: 60000\n",
        "test_images = mnist.test_images() #len: 10000\n",
        "test_labels = mnist.test_labels() #len: 10000\n",
        "type(train_images)# <class 'numpy.ndarray'>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9FWkLRNJZoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_images.shape) # (60000, 28, 28)\n",
        "print(train_labels.shape) # (60000,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75pLkc9EJgx5",
        "colab_type": "text"
      },
      "source": [
        "We want to see the numbers, so we can start by pulling the 0-255 values array directly. Since `train_images` is a long list, you can select one member of it with an index, like `first_image=train_images[0]`. The array you get back is the data representation of the pixel scan of the handwritten digits. This looks visually like there is some sort of structured image here, but it's difficult to read directly. Worse, it's doing a linewrap and we don't even see it presented as pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG_qe1KSJcnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_image = train_images[0]\n",
        "first_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rQ93_R8MtIM",
        "colab_type": "text"
      },
      "source": [
        "We can print wide by setting `numpy.set_printoptions()` to a wide linewidth and printing again - now it looks kind of like a 5, but backwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsW4uGT3L7g6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " np.set_printoptions(linewidth=400)\n",
        "print(first_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-mKTEbKM8T6",
        "colab_type": "text"
      },
      "source": [
        "Since the values are labeled in the `train_labels` object, we can select from the `train_labels` object using the same index: the label for `train_images[0]` is `train_labels[0]`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh9J6YCwOJoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGS5kKZPOP5R",
        "colab_type": "text"
      },
      "source": [
        "An ugly 5 that prints in numbers backwards isn't very nice, we want to print what they should look like. So I'll import `matplotlib` and use that to plot that array, assigning each pixel a grayscale color and plotting that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9_sS0R2OLVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bshwL274OdBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://stackoverflow.com/questions/42353676/display-mnist-image-using-matplotlib\n",
        "def print_mnist_image(image):\n",
        "    # image = np.array(image, dtype='float')\n",
        "    # pixels = image.reshape((28, 28))\n",
        "    pixels=image\n",
        "    plt.imshow(pixels, cmap='gray_r')#cmap='gray' will read images inverted \n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh3c6HjXOh8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_mnist_image(first_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqEa6MlIOi6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_mnist_image(train_images[1])\n",
        "print(\"Label:\",train_labels[1])\n",
        "print_mnist_image(train_images[2])\n",
        "print(\"Label:\",train_labels[2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjw20pujO71Z",
        "colab_type": "text"
      },
      "source": [
        "So you can just chain the index for both together in a loop, and run down an index. `for index in range(0,5)` gives a list of numbers from 0-4 which it can iterate down. Then we put that index into the `train_images` and the `train_labels` objects separately, and print them together in sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvwjb35eOlBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for index in range(0,5):\n",
        "    image=train_images[index]\n",
        "    label=train_labels[index]\n",
        "    print('Label:',label)\n",
        "    print_mnist_image(image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69B4wqegPQhQ",
        "colab_type": "text"
      },
      "source": [
        "### Normalize the images.\n",
        "'Artificial Neural Networks seem to learn best when they have small, centered values' - Victor Zhou. So we convert the grayscale with max pixels = 255 to ratio, then subtract 0.5 to center the ratio at 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkbsTyyQO2mY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_train_images = (train_images / 255) - 0.5\n",
        "n_test_images = (test_images / 255) - 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSyV7iVZPZ7c",
        "colab_type": "text"
      },
      "source": [
        "### Flatten the images.\n",
        "Artificial neural networks are a flattened, 2-D model, so they require a 1-D input. Using the `.reshape()` method from earlier. This method works the same way on any numpy.ndarray object\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WVUxl-qPWsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_train_images = n_train_images.reshape((-1, 784))\n",
        "f_test_images = n_test_images.reshape((-1, 784))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi8YJnroPhsa",
        "colab_type": "text"
      },
      "source": [
        "The above didn't change the length (60000) but htey changed the shape to 784*1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0tC6b6_Pflh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(n_train_images.shape) \n",
        "print(n_test_images.shape)  \n",
        "print(f_train_images.shape) # (60000, 784)\n",
        "print(f_test_images.shape)  # (10000, 784)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJsRevQWPm4p",
        "colab_type": "text"
      },
      "source": [
        "### BUILD THE MODEL \n",
        "'Every Keras model is either built using the Sequential class, which represents a linear stack of layers, or the functional Model class, which is more customizeable. Weâ€™ll be using the simpler Sequential model, since our network is indeed a linear stack of layers.' - Victor Zhou\n",
        "Keras has functions to easily construct an artificial neural network:\n",
        "- `from keras.models import Sequential` - the model holder. Sequential accepts a list of layers objects, like [dense_layer_1, dense_layer_2, conclusion_layer]\n",
        "\n",
        "- `from keras.layers import Dense` - the layer object. Accepts args for number of nodes in layer, activation algorithm, and input_shape.\n",
        "\n",
        "Keras has very well developed docstrings which are practically tutorials. You can access a module or function's docstring like `print(function.__doc__)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCALGkftQBZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential #the model holder. Sequential accepts a list of layers objects, like [dense_layer_1, dense_layer_2, conclusion_layer]\n",
        "from keras.layers import Dense #the layer object. Accepts args for number of nodes in layer, activation algorithm, and input_shape for "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGHDY37EPk2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(Sequential.__doc__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXUdYYAJQIaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(Dense.__doc__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iijcfalcQLGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2_64_flattened = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(784,)), #input_shape is required for input layer only\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax') #the conclusion is reached here\n",
        "]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prCZmRlxQOjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model_2_64_flattened"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAfTuThUQPnK",
        "colab_type": "text"
      },
      "source": [
        "- *ReLU*: Rectified Linear Activation Unit: linear activation with slope and 0 value for negatives: f(-1)=0, f(0)=0, F(1)=1\n",
        "- *Softmax*: takes as input a vector of K real numbers, and normalizes it into a probability distribution consisting of K probabilities proportional to the exponentials of the input numbers. That is, prior to applying softmax, some vector components could be negative, or greater than one; and might not sum to 1; but after applying softmax, each component will be in the interval {\\displaystyle (0,1)}(0,1), and the components will add up to 1, so that they can be interpreted as probabilities. Furthermore, the larger input components will correspond to larger probabilities. Softmax is often used in neural networks, to map the non-normalized output of a network to a probability distribution over predicted output classes.\n",
        "\n",
        "###COMPILE THE MODEL \n",
        "Decide 3 factors: Optimizer, Loss Function, Gradient \n",
        "- accuracy is the simplest metric, (number correctly classified) / (total classified)\n",
        "- why is metrics a list? You can have multiple metrics. See this tutorial for some examples: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
        "- metrics also accepts other args, like 'MSE' and 'AUC'\n",
        "- 'AUC' demo here: #https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
        "- Categorical crossentropy: https://en.wikipedia.org/wiki/Cross_entropy\n",
        "- In information theory, the cross entropy between two probability distributions and over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set if a coding scheme used for the set is optimized for an estimated probability distribution, rather than the true distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coblPMsyQdog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(Sequential.compile.__doc__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE5IL3HpQsNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile( #run the compile() method on the \n",
        "  optimizer='adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'], \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV5hcoTWYlm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dir(model)\n",
        "model.inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHII8l3XQwgs",
        "colab_type": "text"
      },
      "source": [
        "### TRAIN THE MODEL\n",
        "The `train_labels` are integer values, but to use a neural network, what we really want is a set of categories for the neural network to predict - it doesn't need to understand the number value '5', it only needs to know that this is the fifth labeled category. So we convert any category set into a categorical array. the to_categorical() array output has a LENGTH equal to the number of labels, and a WIDTH equal to the number of possible values, or number of categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ-vPJWCRRE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9ZR_EMdZBOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels[:5] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQA_qcHAQvQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_categorical=to_categorical([2, 0, 1, 1, 1, 1, 0])\n",
        "sample_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmrTetbKQ3DB",
        "colab_type": "text"
      },
      "source": [
        "This is structured as a numpy n-dimensional array with 7 rows of 3 cells each.\n",
        "\n",
        "Because they're numbers, we can't assign categories directly to this. As an aside, if we were to list incoming booking channels as a training value, we would use this code to convert:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5p1SrlcRGhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "channel_list=['turnkeyVR.com', 'AirBnB','VRBO','VRBO','VRBO','VRBO','AirBnB']\n",
        "channel_set=list(set(channel_list))\n",
        "channel_set.sort()\n",
        "channel_set #it is now alphabetized in a standardized way\n",
        "channel_dict={} #initialize empty dict \n",
        "channel_index=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg6QezlQRJvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for channel in channel_set: \n",
        "    channel_dict[channel]=channel_index #channel_dict['AirBnB'=0]\n",
        "    channel_index+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZwwWgSLRMkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "channel_dict #{'AirBnB': 0, 'TurnkeyVR.com': 1, 'VRBO': 2}\n",
        "channel_list_numeric=[channel_dict[s] for s in channel_list]\n",
        "channel_list_numeric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEgbHrXDZ0tD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_categorical(channel_list_numeric) #The resulting \n",
        "to_categorical(channel_list_numeric)==sample_categorical #True :) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOhdTuHDRd3i",
        "colab_type": "text"
      },
      "source": [
        "in our test case, we use train_labels list, which is already a set of integers from 0 to 9. Therefore: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wu1oQ3bRN1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(to_categorical(train_labels))==len(train_labels) #there is 1 row for each of the 60,000 test "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6sy3sSjaQ5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(to_categorical(train_labels)[0])==10 #and in each row there are 10 possible values, and they are 'one hot', no partial classifications here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NydFdPVOaf-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(to_categorical(train_labels)[0])==len(list(set(train_labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cSaBTXwaf83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEPukSSLRjKq",
        "colab_type": "text"
      },
      "source": [
        "Run the code to fit the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyRBFNiZRdfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(Sequential.fit.__doc__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZv3ZCncRlrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit(\n",
        "  x=f_train_images, #inputs to train on \n",
        "  y=to_categorical(train_labels), #correct outputs to validate accuracy by \n",
        "  epochs=15, #train for 5 rounds through the data \n",
        "  batch_size=32, #number of samples per gradient update; default is 32 \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z1dWqqKeBBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.machinecurve.com/index.php/2019/10/08/how-to-visualize-the-training-process-in-keras/\n",
        "plt.plot(history.history['accuracy'], label='(training data)')\n",
        "#plt.plot(history.history['val_accuracy'], label='MAE (validation data)')\n",
        "plt.title('Keras_demo accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYdbFm8XRqI6",
        "colab_type": "text"
      },
      "source": [
        "###TEST THE MODEL \n",
        " you should have a separate set of training data that wasn't in your initial training set, this is the Validation dataset. If your neural network is complex  enough (and your number of samples is small), it's possible for it to just learn every example specifically. This is 'overfitting', and it's when your model has high accuracy in the training dataset and low accuracy in the validation dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiRjJ59DRnmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(\n",
        "  x=f_test_images,\n",
        "  y=to_categorical(test_labels)\n",
        ") #[0.11067571075819432, 0.9656999707221985]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKY-4n61RxFK",
        "colab_type": "text"
      },
      "source": [
        "This does not require epochs or batch size.\n",
        "evaluate() returns an array containing the test loss followed by any metrics we specified. Thus, our model achieves a 0.108 test loss and 96.5% test accuracy!\n",
        "This simple neural network is able to read hand-written numbers.\n",
        "\n",
        "###USE THE MODEL \n",
        "save it. The save_weights() method accepts a path for your file save location. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqh7xzb-RwGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(Sequential.save_weights.__doc__)\n",
        "weight_path='./model.h5'\n",
        "model.save_weights(weight_path) #saves it in current working directory, the file name will be model.h5\n",
        "model.load_weights(weight_path) #you could start from here next time if you wanted to re-use this to read hand-written numbers later \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EirndropR8NP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(f_test_images[:5])\n",
        "predictions #gives an array of probabilities for each. These are small, but the highest probability is the one with e-01. We can simplify printing them using argmax:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdmxNKnRdb__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_list=np.argmax(predictions, axis=1) # [7, 2, 1, 0, 4]\n",
        "prediction_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNVWJImdSCtB",
        "colab_type": "text"
      },
      "source": [
        "Finally, produce a nice run alongside each other, showing the digit, the expected label, and our predictions :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sjTaPuRSBVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for index in range(0,5):\n",
        "    print('Our model predicted:\\t',prediction_list[index])\n",
        "    print('The data was labeled:\\t',test_labels[index])\n",
        "    print_mnist_image(test_images[index])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}