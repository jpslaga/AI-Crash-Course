{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Basics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMtYSeFGs2ap11P8af97wJy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpslaga/AI-Crash-Course/blob/master/AI_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNwI83PNDLMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmnK0JM_Dgeh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "5 Principels of Reinforcement Learning\n",
        "\n",
        "#1 The input and output system\n",
        "\"Policy\" is a function that takes a state as input \"input state\" and returns an action as output.  inputs are called \"states\"\n",
        "\n",
        "#2 The reward\n",
        "AI has it performance measured by a reward system. It is a metric that will tell the AI how well it does over time. the ultimate goal of AI will always to maximzie the accumulated reward over time. \n",
        "\n",
        "#3 The AI environment\n",
        "AI environment is a simple framework where you define three things eat each time(f)\n",
        "* The input (the state)\n",
        "* The output (the action)\n",
        "* The reward (the performance method)\n",
        "\n",
        "however there can and are more than these three elements in any given AI environment.\n",
        "\n",
        "#4 Markov decision\n",
        "\n",
        "The Markov Decision Process or MDP is a process that models how the AI interacts over time.  The process starts at t=0 and at each iteration  t=1, t=2. etc. the AI follos the same format of transition\n",
        "1. The AO observes the current state (S1)\n",
        "2. The AI performs the action, A(1)\n",
        "3. The AI receives the reward, R(1) = R(S(1), A(1)).\n",
        "4. The AI enters the following state, S(t+1)\n",
        "\n",
        "the gola is to maximize the accumulated rewards over time, that is the sum of all the rewards received at each transition (t0,t1,t2, etc.)\n",
        "\n",
        "#5 Training and inference\n",
        "Final principle is to understand the difference between training and inference\n",
        "\n",
        "  #Training  pg 38\n",
        "\n",
        "\n",
        "  #Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YClmB8MGhoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The 5 Core Principles Pseudocode\n",
        "\n",
        "class Environment():\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tInitialize the game\n",
        "\t\n",
        "\tdef get_observation(self):\n",
        "\t\tReturn the state of the game \n",
        "\t\n",
        "\tdef get_reward(self, action):\n",
        "\t\tReturn the reward obtained by playing this action\n",
        "\t\n",
        "\tdef update(self, action):\n",
        "\t\tUpdate the environment based on the action specified\n",
        "\n",
        "class AI():\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tInitialize the AI\n",
        "\t\n",
        "\tdef train(self, state_of_the_game, reward):\n",
        "\t\tTrain the AI based on the state of the game and the reward obtained\n",
        "\n",
        "\tdef play_action(self, state_of_the_game):\n",
        "\t\tPlay an action based on the state of the game\n",
        "\n",
        "def markov_decision_process_training():\n",
        "\tenv = Environment()\n",
        "\tai = AI() \n",
        "\twhile True:\n",
        "\t\tstate_of_the_game = env.get_observation()\n",
        "\t\taction = ai.play_action(state_of_the_game)\n",
        "\t\treward = env.get_reward(action)\n",
        "\t\tai.train(state_of_the_game, reward)\n",
        "\t\tenv.update(action)\n",
        "\n",
        "def markov_decision_process_inference():\n",
        "\tenv = Environment()\n",
        "\tai = AI() \n",
        "\twhile True:\n",
        "\t\tstate_of_the_game = env.get_observation()\n",
        "\t\taction = ai.play_action(state_of_the_game)\n",
        "\t\tenv.update(action)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}